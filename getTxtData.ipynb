{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请输入要插入的文件名：test\n",
      "请选择要抓取前几页的数据(最多10页)：10\n",
      "正在抓取https://movie.douban.com/subject/11611021/comments\n",
      "正在抓取https://movie.douban.com/subject/11611021/comments?start=20&limit=20&sort=new_score&status=P\n",
      "正在抓取https://movie.douban.com/subject/11611021/comments?start=40&limit=20&sort=new_score&status=P\n",
      "正在抓取https://movie.douban.com/subject/11611021/comments?start=60&limit=20&sort=new_score&status=P\n",
      "正在抓取https://movie.douban.com/subject/11611021/comments?start=80&limit=20&sort=new_score&status=P\n",
      "正在抓取https://movie.douban.com/subject/11611021/comments?start=100&limit=20&sort=new_score&status=P\n",
      "正在抓取https://movie.douban.com/subject/11611021/comments?start=120&limit=20&sort=new_score&status=P\n",
      "正在抓取https://movie.douban.com/subject/11611021/comments?start=140&limit=20&sort=new_score&status=P\n",
      "正在抓取https://movie.douban.com/subject/11611021/comments?start=160&limit=20&sort=new_score&status=P\n",
      "正在抓取https://movie.douban.com/subject/11611021/comments?start=180&limit=20&sort=new_score&status=P\n",
      "数据写入完成\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "headers = {'User-Agent':\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1\"}\n",
    "movie = input('请输入要抓取的豆瓣电影网址：')\n",
    "# movie = 'https://movie.douban.com/subject/11611021'\n",
    "start_url = movie +'/comments'\n",
    "\n",
    "#创建文件保存数据\n",
    "table = input('请输入要插入的文件名：')\n",
    "path = './' + table+'.txt'\n",
    "file = open(path,'w')\n",
    "\n",
    "max = input('请选择要抓取前几页的数据(最多10页)：')\n",
    "\n",
    "def getContent(start_url):\n",
    "    #获得url开始抓取\n",
    "    print('正在抓取'+start_url)\n",
    "    res = requests.get(start_url,headers = headers)\n",
    "    res.encoding = 'utf-8'\n",
    "    soup = BeautifulSoup(res.text,'html.parser')\n",
    "\n",
    "        #开始分析文档内容\n",
    "    comments = soup.select('.comment-item')\n",
    "    for comment in comments:\n",
    "        username = comment.find('a')['title'] and comment.find('a')['title'] or ''\n",
    "        try:\n",
    "            rating = comment.find('span',class_='rating')['title'] and comment.find('span',class_='rating')['title'] or ''\n",
    "        except:\n",
    "            continue\n",
    "        time = comment.find('span',class_='comment-time').text.strip() and comment.find('span',class_='comment-time').text.strip() or ''\n",
    "        content = comment.find('p').text.strip() and comment.find('p').text.strip() or ''\n",
    "        vote = comment.find('span',class_='votes').text and comment.find('span',class_='votes').text or ''\n",
    "\n",
    "            #写入数据\n",
    "        data = '用户：'+username+'   推荐度：'+rating+'   发表时间：'+time+'  赞同数：'+vote+'\\n\\n'+content+'\\n\\n'\n",
    "        line = '-----------------------------------------------------\\n\\n'\n",
    "        try:\n",
    "            file.write(data)\n",
    "        except:\n",
    "            continue\n",
    "        file.write(line)\n",
    "\n",
    "\n",
    "\n",
    "getContent(start_url)\n",
    "\n",
    "for i in range(1,int(max)):\n",
    "    num = i*20\n",
    "    nextPage = '?start='+str(num)+'&limit=20&sort=new_score&status=P'\n",
    "    nextUrl = movie+'/comments'+nextPage\n",
    "    getContent(nextUrl)\n",
    "\n",
    "\n",
    "file.close()\n",
    "print('数据写入完成')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
